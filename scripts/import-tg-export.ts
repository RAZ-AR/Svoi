// Svoi â€” Import from Telegram Desktop export (HTML format)
// - Imports only posts from the last N months (default: 3)
// - Upsert: re-running updates existing listings, no duplicates
// - Marks "verified author" badge for active posters (3+ listings)
// - --dry-run: preview stats without writing to DB
//
// Usage:
//   npx tsx scripts/import-tg-export.ts --dir=~/Downloads/tg-export --dry-run
//   npx tsx scripts/import-tg-export.ts --dir=~/Downloads/tg-export --months=3
//   npx tsx scripts/import-tg-export.ts --dir=~/Downloads/tg-export --channel=belgrad_serbia

import dotenv from "dotenv";
dotenv.config({ path: ".env.local" });

import * as fs   from "fs";
import * as path from "path";
import { createClient } from "@supabase/supabase-js";

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

const APP_URL = process.env.NEXT_PUBLIC_APP_URL ?? "https://svoi-lac.vercel.app";

// â”€â”€â”€ Args â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const dirArg     = process.argv.find((a) => a.startsWith("--dir="));
const channelArg = process.argv.find((a) => a.startsWith("--channel="));
const monthsArg  = process.argv.find((a) => a.startsWith("--months="));
const DRY_RUN    = process.argv.includes("--dry-run");

if (!dirArg) {
  console.error("âŒ  Usage: npx tsx scripts/import-tg-export.ts --dir=~/Downloads/tg-export [--dry-run] [--months=3]");
  process.exit(1);
}

const BASE_DIR  = dirArg.split("=")[1].replace(/^~/, process.env.HOME ?? "");
const ONLY      = channelArg ? channelArg.split("=")[1] : null;
const MONTHS    = monthsArg  ? Number(monthsArg.split("=")[1]) : 3;

// Cutoff: only import posts newer than this
const CUTOFF = new Date();
CUTOFF.setMonth(CUTOFF.getMonth() - MONTHS);

// Threshold for "verified author" badge (N or more listings = verified)
const VERIFIED_THRESHOLD = 3;

const IMPORT_USER_TG_ID = 888888888;

// â”€â”€â”€ HTML parsing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

interface TgPost {
  id:             number;
  text:           string;
  photoRel:       string | null;
  date:           Date;
  authorName:     string | null;
}

function stripHtml(html: string): string {
  return html
    .replace(/<br\s*\/?>/gi, "\n")
    .replace(/<\/p>/gi, "\n")
    .replace(/<[^>]+>/g, "")
    .replace(/&amp;/g, "&").replace(/&lt;/g, "<").replace(/&gt;/g, ">")
    .replace(/&quot;/g, '"').replace(/&#39;/g, "'").replace(/&nbsp;/g, " ")
    .replace(/\n{3,}/g, "\n\n")
    .trim();
}

function parseHtmlFile(html: string): TgPost[] {
  const posts: TgPost[] = [];
  const blocks = html.split(/(?=<div class="message)/);

  for (const block of blocks) {
    const idMatch = block.match(/id="message(\d+)"/);
    if (!idMatch) continue;
    const id = Number(idMatch[1]);

    // Text
    let text = "";
    const textMatch = block.match(/<div class="text[^"]*">([\s\S]*?)<\/div>/);
    if (textMatch) text = stripHtml(textMatch[1]);

    // Photo
    let photoRel: string | null = null;
    const photoMatch =
      block.match(/href="(photos\/[^"]+\.(?:jpg|jpeg|png|webp))"/i) ??
      block.match(/src="(photos\/[^"]+\.(?:jpg|jpeg|png|webp))"/i);
    if (photoMatch) photoRel = photoMatch[1];

    // Date â€” search for title="DD.MM.YYYY HH:MM:SS" anywhere in block
    // Handles: class="pull_right date details", timezone suffix "UTC+01:00", etc.
    let date = new Date(0); // epoch = guaranteed "too old", filtered out if unparseable
    const dateMatch = block.match(/title="(\d{2})\.(\d{2})\.(\d{4}) (\d{2}):(\d{2}):(\d{2})/);
    if (dateMatch) {
      const [, dd, mm, yyyy, hh, min, ss] = dateMatch.map(Number);
      date = new Date(yyyy, mm - 1, dd, hh, min, ss);
    }

    // Author name (only in channels with signed posts)
    let authorName: string | null = null;
    const fromMatch = block.match(/<div class="from_name">([^<]+)</);
    if (fromMatch) authorName = fromMatch[1].trim() || null;

    if (text.trim() || photoRel) {
      posts.push({ id, text, photoRel, date, authorName });
    }
  }

  return posts;
}

// â”€â”€â”€ Category + price â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const CATEGORY_RULES = [
  { slug: "rent",      re: /Ğ°Ñ€ĞµĞ½Ğ´|ÑĞ´Ğ°Ğ¼|ÑĞ´Ğ°Ñ|ÑĞ½Ğ¸Ğ¼Ñƒ|ĞºĞ²Ğ°Ñ€Ñ‚Ğ¸Ñ€|ĞºĞ¾Ğ¼Ğ½Ğ°Ñ‚|Ğ¶Ğ¸Ğ»ÑŒ|rent\b/i },
  { slug: "jobs",      re: /Ñ€Ğ°Ğ±Ğ¾Ñ‚|Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ñ|Ğ¸Ñ‰Ñƒ Ñ€Ğ°Ğ±Ğ¾Ñ‚|Ñ€ĞµĞ·ÑĞ¼Ğµ|Ğ½Ğ°Ğ½Ğ¸Ğ¼Ğ°|job|vacancy/i },
  { slug: "transport", re: /Ğ°Ğ²Ñ‚Ğ¾\b|Ğ¼Ğ°ÑˆĞ¸Ğ½|Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»|bmw|volkswagen|toyota|ford|hyundai|kia/i },
  { slug: "education", re: /Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸|ĞºÑƒÑ€Ñ|Ñ€ĞµĞ¿ĞµÑ‚Ğ¸Ñ‚Ğ¾Ñ€|ÑƒÑ€Ğ¾Ğº\b|ÑƒÑ‡Ñƒ\b|lesson/i },
  { slug: "services",  re: /ÑƒÑĞ»ÑƒĞ³|Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ñƒ|ÑĞ´ĞµĞ»Ğ°Ñ|Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´|ÑÑ€Ğ¸ÑÑ‚|Ñ€ĞµĞ¼Ğ¾Ğ½Ñ‚|ĞºĞ»Ğ¸Ğ½Ğ¸Ğ½Ğ³|service/i },
  { slug: "meetups",   re: /Ğ²ÑÑ‚Ñ€ĞµÑ‡|Ğ¿Ñ€Ğ¾Ğ³ÑƒĞ»Ğº|Ğ·Ğ½Ğ°ĞºĞ¾Ğ¼ÑÑ‚Ğ²|Ğ¸Ñ‰Ñƒ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸|meetup/i },
  { slug: "stuff",     re: /Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¼|Ğ¿Ñ€Ğ¾Ğ´Ğ°Ñ|Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞµÑ‚ÑÑ|ĞºÑƒĞ¿Ğ»Ñ|Ğ¾Ñ‚Ğ´Ğ°Ğ¼|Ğ´Ğ°Ñ€Ğ¾Ğ¼|Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½|Ğ½Ğ¾ÑƒÑ‚Ğ±ÑƒĞº/i },
];

function detectCategory(text: string): string {
  for (const { slug, re } of CATEGORY_RULES) {
    if (re.test(text)) return slug;
  }
  return "misc";
}

function parsePrice(text: string): { price: number | null; currency: string } {
  const patterns = [
    { re: /([\d][\d\s,.]*)\s*(?:â‚¬|EUR|ĞµĞ²Ñ€Ğ¾)/i,    currency: "EUR" },
    { re: /([\d][\d\s,.]*)\s*(?:RSD|Ğ´Ğ¸Ğ½|Ğ´Ğ¸Ğ½Ğ°Ñ€)/i, currency: "RSD" },
    { re: /([\d][\d\s,.]*)\s*(?:USD|\$|Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€)/i, currency: "USD" },
  ];
  for (const { re, currency } of patterns) {
    const m = text.match(re);
    if (m) {
      const num = parseFloat(m[1].replace(/\s/g, "").replace(",", "."));
      if (!isNaN(num) && num > 0 && num < 10_000_000) return { price: num, currency };
    }
  }
  return { price: null, currency: "EUR" };
}

function parseTitle(text: string): { title: string; description: string } {
  const lines = text.split("\n").map((l) => l.trim()).filter(Boolean);
  if (!lines.length) return { title: "ĞĞ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ", description: "" };
  return { title: lines[0].slice(0, 120) || "ĞĞ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ", description: lines.slice(1).join("\n") };
}

// â”€â”€â”€ Photo upload â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function uploadLocalPhoto(absPath: string, channel: string, msgId: number): Promise<string | null> {
  if (!fs.existsSync(absPath)) return null;
  try {
    const buf  = fs.readFileSync(absPath);
    const ext  = absPath.endsWith(".png") ? "png" : "jpg";
    const dest = `tg-import/${channel.toLowerCase()}/${msgId}.${ext}`;
    const { error } = await supabase.storage
      .from("images").upload(dest, buf, { contentType: `image/${ext}`, upsert: true });
    if (error) return null;
    const { data: { publicUrl } } = supabase.storage.from("images").getPublicUrl(dest);
    return publicUrl;
  } catch { return null; }
}

// â”€â”€â”€ Import user â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function getImportUserId(): Promise<string> {
  const { data } = await supabase.from("users").select("id")
    .eq("telegram_id", IMPORT_USER_TG_ID).single();
  if (data) return data.id;
  const { data: created, error } = await supabase.from("users")
    .insert({ telegram_id: IMPORT_USER_TG_ID, first_name: "Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸Ğ· Telegram", completed_profile: true })
    .select("id").single();
  if (error || !created) throw new Error(`Cannot create import user: ${error?.message}`);
  return created.id;
}

// â”€â”€â”€ Mark verified authors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// After import: authors with VERIFIED_THRESHOLD+ listings = verified badge

async function markVerifiedAuthors(channels: string[]) {
  console.log(`\nğŸ…  Marking verified authors (${VERIFIED_THRESHOLD}+ listings)...`);

  for (const channel of channels) {
    // Count listings per author in this channel
    const { data: counts } = await supabase
      .from("listings")
      .select("tg_author_username, tg_author_id")
      .eq("tg_channel", channel)
      .not("tg_author_username", "is", null);

    if (!counts?.length) {
      // No named authors â€” fall back to channel-level verification:
      // if the channel contributed 10+ listings, mark all as verified
      const { count } = await supabase
        .from("listings")
        .select("id", { count: "exact", head: true })
        .eq("tg_channel", channel)
        .eq("status", "active");

      if ((count ?? 0) >= 10) {
        const { error } = await supabase
          .from("listings")
          .update({ tg_author_verified: true })
          .eq("tg_channel", channel);
        if (!error) console.log(`    âœ“ @${channel} â€” channel verified (${count} listings)`);
      }
      continue;
    }

    // Count by author name
    const authorCounts: Record<string, number> = {};
    for (const row of counts) {
      const key = row.tg_author_username ?? `id:${row.tg_author_id}`;
      authorCounts[key] = (authorCounts[key] ?? 0) + 1;
    }

    const verifiedAuthors = Object.entries(authorCounts)
      .filter(([, c]) => c >= VERIFIED_THRESHOLD)
      .map(([name]) => name);

    if (verifiedAuthors.length) {
      await supabase
        .from("listings")
        .update({ tg_author_verified: true })
        .eq("tg_channel", channel)
        .in("tg_author_username", verifiedAuthors);
      console.log(`    âœ“ @${channel} â€” ${verifiedAuthors.length} verified author(s): ${verifiedAuthors.join(", ")}`);
    } else {
      console.log(`    Â· @${channel} â€” no authors reached threshold yet`);
    }
  }
}

// â”€â”€â”€ Cross-channel fingerprint map (shared across all channel imports) â”€â”€â”€â”€â”€â”€â”€â”€
// fingerprint (first 100 chars) â†’ listing id already in DB
const crossChannelMap = new Map<string, string>();

function textFingerprint(text: string): string {
  return text.slice(0, 100).trim().toLowerCase().replace(/\s+/g, " ");
}

// â”€â”€â”€ Process one channel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function importChannel(
  channelDir: string,
  channelName: string,
  catMap: Record<string, number>,
  importUserId: string
): Promise<{ imported: number; updated: number; skipped: number; tooOld: number }> {

  const htmlFiles = fs.readdirSync(channelDir)
    .filter((f) => f.match(/^messages\d*\.html$/))
    .sort((a, b) => {
      const na = Number(a.replace("messages", "").replace(".html", "") || "1");
      const nb = Number(b.replace("messages", "").replace(".html", "") || "1");
      return na - nb;
    });

  if (!htmlFiles.length) {
    console.log(`    âš  No messages*.html files found`);
    return { imported: 0, updated: 0, skipped: 0, tooOld: 0 };
  }

  // Parse all HTML files and deduplicate by message ID
  const seen = new Set<number>();
  const allPosts: TgPost[] = [];
  for (const file of htmlFiles) {
    const html  = fs.readFileSync(path.join(channelDir, file), "utf-8");
    for (const post of parseHtmlFile(html)) {
      if (!seen.has(post.id)) { seen.add(post.id); allPosts.push(post); }
    }
  }

  // Sort by date descending (newest first)
  allPosts.sort((a, b) => b.date.getTime() - a.date.getTime());

  const recent = allPosts.filter((p) => p.date >= CUTOFF);
  const tooOld = allPosts.length - recent.length;

  // Keep only posts that have meaningful text (min 10 chars)
  const noText    = recent.filter((p) => p.text.trim().length < 10).length;
  const withText  = recent.filter((p) => p.text.trim().length >= 10);

  // Remove intra-export duplicates (same first 80 chars = same listing reposted)
  const textSeen  = new Set<string>();
  let   intraDupes = 0;
  const toImport: TgPost[] = [];
  for (const p of withText) {
    const fp = p.text.slice(0, 80).trim().toLowerCase();
    if (fp && textSeen.has(fp)) { intraDupes++; continue; }
    if (fp) textSeen.add(fp);
    toImport.push(p);
  }

  const withPhoto = toImport.filter((p) => p.photoRel).length;

  console.log(`    Total in export:    ${allPosts.length}`);
  console.log(`    Older than ${MONTHS}m:    ${tooOld} â†’ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾`);
  console.log(`    Ğ‘ĞµĞ· Ñ‚ĞµĞºÑÑ‚Ğ°:         ${noText} â†’ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾`);
  console.log(`    Ğ”ÑƒĞ±Ğ»ĞµĞ¹ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¾:     ${intraDupes}`);
  console.log(`    Ğ¡ Ñ„Ğ¾Ñ‚Ğ¾:             ${withPhoto}`);
  console.log(`    Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ Ğº Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñƒ:   ${toImport.length}`);

  if (DRY_RUN) {
    console.log(`\n    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 8):`);
    for (const p of toImport.slice(0, 8)) {
      const { title } = parseTitle(p.text);
      const cat = detectCategory(p.text);
      const { price, currency } = parsePrice(p.text);
      const priceStr = price ? `${price} ${currency}` : "Ñ†ĞµĞ½Ğ° Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ°";
      console.log(`      [${p.id}] [${cat}] ${title.slice(0, 55)} â€” ${priceStr}`);
    }
    if (toImport.length > 8) console.log(`      ... Ğ¸ ĞµÑ‰Ñ‘ ${toImport.length - 8}`);
    return { imported: 0, updated: 0, skipped: 0, tooOld, dryCount: toImport.length } as any;
  }

  console.log("");

  let imported    = 0;
  let updated     = 0;
  let crossDupes  = 0;
  let skipped     = 0;

  for (const post of toImport) {
    const fp = textFingerprint(post.text);

    // â”€â”€ Cross-channel duplicate: same listing already imported from another channel â”€â”€
    if (crossChannelMap.has(fp)) {
      const existingId = crossChannelMap.get(fp)!;

      // Append this channel as an additional source tag
      const { data: existing } = await supabase
        .from("listings")
        .select("tg_sources")
        .eq("id", existingId)
        .single();

      const raw = existing?.tg_sources;
      const sources: { channel: string; message_id: number }[] =
        Array.isArray(raw) ? raw : (typeof raw === "string" ? JSON.parse(raw) : []);

      // Only add if this channel isn't already in sources
      const alreadyTagged = sources.some((s) => s.channel === channelName);
      if (!alreadyTagged) {
        sources.push({ channel: channelName, message_id: post.id });
        await supabase
          .from("listings")
          .update({ tg_sources: sources })
          .eq("id", existingId);
        process.stdout.write(`    â†©  [${post.id}] cross-dupe â†’ added tag @${channelName}\n`);
      }

      crossDupes++;
      continue;
    }

    const { title, description } = parseTitle(post.text);
    const { price, currency }    = parsePrice(post.text);
    const catSlug                = detectCategory(post.text);
    const categoryId             = catMap[catSlug] ?? catMap["misc"];

    let images: { url: string }[] = [];
    if (post.photoRel) {
      const absPath = path.join(channelDir, post.photoRel);
      const url = await uploadLocalPhoto(absPath, channelName, post.id);
      if (url) images = [{ url }];
    }

    // Upsert on (tg_channel, tg_message_id)
    const { error, data } = await supabase
      .from("listings")
      .upsert({
        user_id:              importUserId,
        category_id:          categoryId,
        title,
        description:          description || null,
        price,
        currency,
        images:               JSON.stringify(images),
        status:               "active",
        created_at:           post.date.toISOString(),
        tg_channel:           channelName,
        tg_message_id:        post.id,
        tg_author_username:   post.authorName,
        tg_sources:           JSON.stringify([]),
      }, {
        onConflict:       "tg_channel,tg_message_id",
        ignoreDuplicates: false,
      })
      .select("id");

    if (error) {
      console.warn(`    âš   [${post.id}]: ${error.message}`);
      skipped++;
    } else {
      const listingId = (data as any)?.[0]?.id;
      if (listingId) crossChannelMap.set(fp, listingId); // register for cross-channel dedup
      imported++;
      process.stdout.write(`    âœ“  [${post.id}] ${title.slice(0, 58)}\n`);
    }
  }

  console.log(`    â†’ upserted: ${imported} | cross-dupes merged: ${crossDupes} | skipped: ${skipped}\n`);
  return { imported, updated, skipped, tooOld };
}

// â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function main() {
  if (!fs.existsSync(BASE_DIR)) {
    console.error(`âŒ  Not found: ${BASE_DIR}`);
    process.exit(1);
  }

  const allDirs  = fs.readdirSync(BASE_DIR, { withFileTypes: true })
    .filter((d) => d.isDirectory()).map((d) => d.name);
  const channels = ONLY ? allDirs.filter((d) => d.toLowerCase() === ONLY.toLowerCase()) : allDirs;

  if (!channels.length) {
    console.error(`âŒ  No channel folders found in ${BASE_DIR}`);
    process.exit(1);
  }

  console.log(`ğŸš€  Svoi â€” Telegram Export Importer${DRY_RUN ? " [DRY RUN â€” Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑˆĞµÑ‚ÑÑ]" : ""}`);
  console.log(`    Dir:      ${BASE_DIR}`);
  console.log(`    Channels: ${channels.join(", ")}`);
  console.log(`    Filter:   Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ ${MONTHS} Ğ¼ĞµÑÑÑ†Ğ° (Ñ ${CUTOFF.toLocaleDateString("ru-RU")})\n`);

  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  const { data: cats } = await supabase.from("categories").select("id, slug");
  const catMap       = Object.fromEntries((cats ?? []).map((c: any) => [c.slug, c.id]));
  const importUserId = await getImportUserId();

  let totalImported = 0;
  let totalSkipped  = 0;
  let totalOld      = 0;
  let totalDry      = 0;

  for (const channel of channels) {
    console.log(`ğŸ“¡  @${channel}`);
    const res = await importChannel(path.join(BASE_DIR, channel), channel, catMap, importUserId) as any;
    if (DRY_RUN) {
      totalDry += res.dryCount ?? 0;
    } else {
      console.log(`    â†’ upserted: ${res.imported} | skipped: ${res.skipped} | too old: ${res.tooOld}\n`);
    }
    totalImported += res.imported;
    totalSkipped  += res.skipped;
    totalOld      += res.tooOld;
  }

  console.log("â”€".repeat(50));

  if (DRY_RUN) {
    console.log(`ğŸ“Š  Ğ˜Ñ‚Ğ¾Ğ³Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾: ${totalDry} Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğ¹`);
    console.log(`    Ğ¡Ñ‚Ğ°Ñ€Ñ‹Ñ… (Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾):         ${totalOld}`);
    console.log(`\n    Ğ’ÑÑ‘ Ğ²Ñ‹Ğ³Ğ»ÑĞ´Ğ¸Ñ‚ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾? Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸ Ğ±ĞµĞ· --dry-run:`);
    console.log(`    npx tsx scripts/import-tg-export.ts --dir=${BASE_DIR} --months=${MONTHS}`);
    return;
  }

  // Mark verified authors across all imported channels
  await markVerifiedAuthors(channels);

  console.log(`ğŸ‰  Done! upserted: ${totalImported} | skipped: ${totalSkipped} | too old (ignored): ${totalOld}`);
  console.log(`\n    View at: ${APP_URL}/home`);
}

main().catch((err) => {
  console.error("Fatal:", err);
  process.exit(1);
});
